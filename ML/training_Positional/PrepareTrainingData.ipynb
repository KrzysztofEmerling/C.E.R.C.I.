{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fbc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "piece_map = {\n",
    "    chess.PAWN: 0,\n",
    "    chess.KNIGHT: 1,\n",
    "    chess.BISHOP: 2,\n",
    "    chess.ROOK: 3,\n",
    "    chess.QUEEN: 4,\n",
    "    chess.KING: 5\n",
    "}\n",
    "\n",
    "def board_to_tensor_1d(board):\n",
    "    \"\"\"\n",
    "    Konwersja pozycji do 1D tensora: 12 * 8 * 8 = 768\n",
    "    \"\"\"\n",
    "    tensor = np.zeros((12, 64), dtype=np.float32)\n",
    "\n",
    "    for sq in chess.SQUARES:\n",
    "        piece = board.piece_at(sq)\n",
    "        if piece:\n",
    "            base = piece_map[piece.piece_type]\n",
    "            if piece.color == chess.BLACK:\n",
    "                base += 6\n",
    "            tensor[base, sq] = 1.0\n",
    "\n",
    "    return tensor.flatten()  # 768-elementowy wektor\n",
    "\n",
    "def load_and_prepare_gen(path, n=None):\n",
    "    count = 0\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            fen, moves_str = line.split(\"|\")\n",
    "            move_pairs = moves_str.split(\";\")\n",
    "\n",
    "            board = chess.Board(fen)\n",
    "            p_score = None\n",
    "\n",
    "            for mp in move_pairs:\n",
    "                if \":\" not in mp:\n",
    "                    continue\n",
    "\n",
    "                uci, score = mp.split(\":\")\n",
    "                score = float(score)\n",
    "\n",
    "                # eliminacja matÃ³w\n",
    "                if score > 4900:\n",
    "                    continue\n",
    "\n",
    "                #eliminacja beta prunning\n",
    "                if p_score is None:\n",
    "                    p_score = score\n",
    "                elif p_score < score:\n",
    "                    p_score = score\n",
    "\n",
    "                    # ruch\n",
    "                    try:\n",
    "                        move = chess.Move.from_uci(uci)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    board_copy = board.copy()\n",
    "                    board_copy.push(move)\n",
    "\n",
    "                    # tensor\n",
    "                    x = board_to_tensor_1d(board_copy)\n",
    "\n",
    "                    yield {\n",
    "                        \"fen_after\": board_copy.fen(),\n",
    "                        \"X\": x,\n",
    "                        \"y\": score\n",
    "                    }\n",
    "\n",
    "                    count += 1\n",
    "                    if n is not None and count >= n:\n",
    "                        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e48675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def save_batch(prefix, batch_id, X_batch, y_batch):\n",
    "    np.savez_compressed(f\"{prefix}_{batch_id}.npz\", X=X_batch, y=y_batch)\n",
    "\n",
    "\n",
    "def create_shuffled_split_files(path_input, batch_size=10000, test_size=0.2):\n",
    "    train_X, train_y = [], []\n",
    "    test_X, test_y = [], []\n",
    "    train_id = 0\n",
    "    test_id = 0\n",
    "\n",
    "    for sample in load_and_prepare_gen(path_input):\n",
    "        x = sample[\"X\"]\n",
    "        y = sample[\"y\"]\n",
    "\n",
    "        # losowy split\n",
    "        if random.random() < test_size:\n",
    "            test_X.append(x)\n",
    "            test_y.append(y)\n",
    "\n",
    "            if len(test_X) >= batch_size:\n",
    "                save_batch(\"test\", test_id, np.array(test_X), np.array(test_y))\n",
    "                test_X, test_y = [], []\n",
    "                test_id += 1\n",
    "        else:\n",
    "            train_X.append(x)\n",
    "            train_y.append(y)\n",
    "\n",
    "            if len(train_X) >= batch_size:\n",
    "                save_batch(\"train\", train_id, np.array(train_X), np.array(train_y))\n",
    "                train_X, train_y = [], []\n",
    "                train_id += 1\n",
    "\n",
    "    # resztki\n",
    "    if train_X:\n",
    "        save_batch(\"train\", train_id, np.array(train_X), np.array(train_y))\n",
    "    if test_X:\n",
    "        save_batch(\"test\", test_id, np.array(test_X), np.array(test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53375b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "def npz_batch_generator(pattern, batch_size=512):\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    X_buf, y_buf = [], []\n",
    "\n",
    "    for fname in files:\n",
    "        data = np.load(fname)\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"]\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            X_buf.append(X[i])\n",
    "            y_buf.append(y[i])\n",
    "\n",
    "            if len(X_buf) == batch_size:\n",
    "                yield np.array(X_buf, dtype=np.float32), np.array(y_buf, dtype=np.float32)\n",
    "                X_buf, y_buf = [], []\n",
    "\n",
    "def make_tf_dataset(pattern, batch_size=512):\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(None, 768), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: npz_batch_generator(pattern, batch_size),\n",
    "        output_signature=output_signature\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57276352",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_shuffled_split_files(\"./training/trainingAgresive.txt\", batch_size=48000, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_dense_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(768,)))\n",
    "\n",
    "    num_layers = hp.Int('num_layers', 1, 5)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        num_exp = hp.Int(f'num_exp_{i}', 4, 10)\n",
    "        units = 2 ** num_exp\n",
    "\n",
    "        activation = hp.Choice(f'activation_{i}', ['relu', 'tanh', 'elu'])\n",
    "\n",
    "        model.add(layers.Dense(units=units, activation=activation))\n",
    "\n",
    "        dropout_rate = hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)\n",
    "        if dropout_rate > 0:\n",
    "            model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410994df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "train_ds = make_tf_dataset(\"train_*.npz\", batch_size=512)\n",
    "test_ds  = make_tf_dataset(\"test_*.npz\",  batch_size=512)\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_dense_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=50,\n",
    "    directory=\"bayesian_tuning\",\n",
    "    project_name=\"dense_model\"\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=150,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Najlepsze hiperparametry:\")\n",
    "for param in best_hp.values:\n",
    "    print(param, best_hp.get(param))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChessEnv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
